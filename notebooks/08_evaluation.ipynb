{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 08. Model Evaluation\n",
                "\n",
                "Evaluating a language model is crucial to understand its performance. The most common metric for causal language modeling is **Perplexity**.\n",
                "\n",
                "## Perplexity\n",
                "\n",
                "Perplexity (PPL) is defined as the exponentiated average negative log-likelihood of a sequence. Intuitively, it measures how \"surprised\" the model is by the text. A lower perplexity means the model is less surprised (i.e., predicts the text better).\n",
                "\n",
                "$$ \\text{PPL}(X) = \\exp \\left( -\\frac{1}{t} \\sum_{i=1}^t \\log P(x_i | x_{<i}) \\right) $$\n",
                "\n",
                "where $X = (x_1, \\dots, x_t)$ is the tokenized sequence."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn.functional as F\n",
                "from tqdm.auto import tqdm\n",
                "import math\n",
                "\n",
                "# Dummy model setup for demonstration\n",
                "class DummyModel(torch.nn.Module):\n",
                "    def __init__(self): super().__init__()\n",
                "    def forward(self, x, targets=None):\n",
                "        logits = torch.randn(x.size(0), x.size(1), 1000)\n",
                "        loss = F.cross_entropy(logits.view(-1, 1000), targets.view(-1)) if targets is not None else None\n",
                "        return logits, loss\n",
                "\n",
                "model = DummyModel()\n",
                "device = torch.device(\"cpu\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Calculating Perplexity\n",
                "\n",
                "We can calculate perplexity by evaluating the cross-entropy loss on a validation set. Since CrossEntropyLoss computes the average negative log-likelihood, we simply take the exponential of the loss."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "02b8f90fbd704af6b431f0d595e7b3b9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Validation Perplexity: 1528.83\n"
                    ]
                }
            ],
            "source": [
                "def calculate_perplexity(model, dataloader, device):\n",
                "    model.eval()\n",
                "    total_loss = 0\n",
                "    total_tokens = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
                "            input_ids = batch['input_ids'].to(device)\n",
                "            targets = batch['labels'].to(device)\n",
                "            \n",
                "            # Forward pass to get loss\n",
                "            _, loss = model(input_ids, targets)\n",
                "            \n",
                "            # Accumulate loss (weighted by batch size if needed, but usually mean is fine for fixed batch size)\n",
                "            total_loss += loss.item()\n",
                "            \n",
                "    avg_loss = total_loss / len(dataloader)\n",
                "    perplexity = math.exp(avg_loss)\n",
                "    return perplexity\n",
                "\n",
                "# Dummy dataloader\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "class DummyDataset(Dataset):\n",
                "    def __len__(self): return 10\n",
                "    def __getitem__(self, idx): return {\"input_ids\": torch.randint(0, 1000, (32,)), \"labels\": torch.randint(0, 1000, (32,))}\n",
                "\n",
                "val_loader = DataLoader(DummyDataset(), batch_size=2)\n",
                "\n",
                "ppl = calculate_perplexity(model, val_loader, device)\n",
                "print(f\"Validation Perplexity: {ppl:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Other Metrics\n",
                "\n",
                "While perplexity is the standard, other metrics can be useful depending on the downstream task:\n",
                "- **Accuracy**: Next-token prediction accuracy (not always correlated with generation quality).\n",
                "- **BLEU/ROUGE**: For specific tasks like translation or summarization (requires generating text and comparing to reference).\n",
                "\n",
                "For a general-purpose LLM, we primarily focus on Perplexity and qualitative assessment of generated text."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "NLP",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
